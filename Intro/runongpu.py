# -*- coding: utf-8 -*-
"""RunOnGPU.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14A3KqSz1SkH6889fDiqxG5Q-oEm8zdcX

## Running On The GPU
Find the source for this tutorial in this [link](https://pythonprogramming.net/gpu-deep-learning-neural-network-pytorch/?completed=/convnet-model-deep-learning-neural-network-pytorch/)
If you wanna continue training, either you are going to need extreme patience or high end GPUs :)  

- ### Local Usage
If you run locally
1. You need a high-end CUDA-enabled GPU
2. The CUDA toolkit.(Download and Install)
3. cuDNN to match the CUDA toolkit.(Download and Extract)

- ### Cloud Usage
Linode GPUs has good offers!

## What is CUDA?
Compute Unified Device Architecture, CUDA, is a parallel computing platform and programming model invented by NVIDIA. It enables developers to speed up compute-intensive applications by harnessing the power of GPUs for the parallelizable part of the computation.
CUDA is a standard feature in all NVIDIA GeForce, Quadro, and Tesla GPUs as well as NVIDIA GRID solutions.

## What is cuDNN?
NVIDIA CUDA Deep Neural Network (cuDNN) is a GPU-accelerated library of primitives for deep neural networks. It provides highly tuned implementations of routines arising frequently in DNN applications.

### CUDA Vs cuDNN

With CUDA, developers are able to dramatically speed up computing applications by harnessing the power of GPUs. And cuDNN is a Cuda Deep neural network library which is accelerated on GPU's. It's built on underlying Cuda framework.
"""